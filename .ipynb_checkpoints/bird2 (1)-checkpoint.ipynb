{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cerDfFtIWrXn",
    "outputId": "c560f16b-ed6e-40a0-bf44-420214f2bdc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (689 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from soundfile) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.10.3.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpZcPUCtXZ2n",
    "outputId": "814c2436-1466-4823-a704-8422e1fff067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "Collecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (0.17.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (0.51.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.14.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.24.0)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (20.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.25.11)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
      "Building wheels for collected packages: librosa, audioread, resampy\n",
      "  Building wheel for librosa (setup.py): started\n",
      "  Building wheel for librosa (setup.py): finished with status 'done'\n",
      "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201381 sha256=cab9250a4187c48237d741dbc705bf95f9ad9f27b2d6e0820a3343f18e0c4289\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\aa\\5a\\92\\d52f6f8560ff05a2525e6030a1903412df876714241fb76802\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23146 sha256=2253bd587e8bf7fc4ff282b4111f08edb6895301e0d236ee6976e4e4b4d08bec\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\49\\5a\\e4\\df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\n",
      "  Building wheel for resampy (setup.py): started\n",
      "  Building wheel for resampy (setup.py): finished with status 'done'\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320724 sha256=79dd10c20df08a8d305befa4b3aee05a1c9a134d92195343ada4b44eca1316ba\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\6f\\d1\\5d\\f13da53b1dcbc2624ff548456c9ffb526c914f53c12c318bb4\n",
      "Successfully built librosa audioread resampy\n",
      "Installing collected packages: audioread, resampy, appdirs, pooch, librosa\n",
      "Successfully installed appdirs-1.4.4 audioread-2.1.9 librosa-0.8.0 pooch-1.3.0 resampy-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split_folders in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/sima/.local/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /home/sima/anaconda3/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/sima/.local/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/sima/.local/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in /home/sima/anaconda3/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Asus\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - git\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    git-2.23.0                 |       h6bb4b03_0        10.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        10.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  git                pkgs/main/win-64::git-2.23.0-h6bb4b03_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "git-2.23.0           | 10.5 MB   |            |   0% \n",
      "git-2.23.0           | 10.5 MB   |            |   0% \n",
      "git-2.23.0           | 10.5 MB   | 1          |   1% \n",
      "git-2.23.0           | 10.5 MB   | 2          |   2% \n",
      "git-2.23.0           | 10.5 MB   | 4          |   4% \n",
      "git-2.23.0           | 10.5 MB   | 5          |   6% \n",
      "git-2.23.0           | 10.5 MB   | 7          |   8% \n",
      "git-2.23.0           | 10.5 MB   | 9          |  10% \n",
      "git-2.23.0           | 10.5 MB   | #1         |  11% \n",
      "git-2.23.0           | 10.5 MB   | #3         |  13% \n",
      "git-2.23.0           | 10.5 MB   | #5         |  15% \n",
      "git-2.23.0           | 10.5 MB   | #6         |  17% \n",
      "git-2.23.0           | 10.5 MB   | #8         |  19% \n",
      "git-2.23.0           | 10.5 MB   | ##         |  21% \n",
      "git-2.23.0           | 10.5 MB   | ##2        |  22% \n",
      "git-2.23.0           | 10.5 MB   | ##4        |  24% \n",
      "git-2.23.0           | 10.5 MB   | ##6        |  26% \n",
      "git-2.23.0           | 10.5 MB   | ##7        |  28% \n",
      "git-2.23.0           | 10.5 MB   | ##9        |  30% \n",
      "git-2.23.0           | 10.5 MB   | ###1       |  31% \n",
      "git-2.23.0           | 10.5 MB   | ###3       |  33% \n",
      "git-2.23.0           | 10.5 MB   | ###4       |  35% \n",
      "git-2.23.0           | 10.5 MB   | ###8       |  39% \n",
      "git-2.23.0           | 10.5 MB   | ####       |  41% \n",
      "git-2.23.0           | 10.5 MB   | ####2      |  43% \n",
      "git-2.23.0           | 10.5 MB   | ####4      |  45% \n",
      "git-2.23.0           | 10.5 MB   | ####6      |  47% \n",
      "git-2.23.0           | 10.5 MB   | ####8      |  48% \n",
      "git-2.23.0           | 10.5 MB   | #####      |  50% \n",
      "git-2.23.0           | 10.5 MB   | #####2     |  52% \n",
      "git-2.23.0           | 10.5 MB   | #####4     |  54% \n",
      "git-2.23.0           | 10.5 MB   | #####6     |  56% \n",
      "git-2.23.0           | 10.5 MB   | #####7     |  58% \n",
      "git-2.23.0           | 10.5 MB   | #####9     |  60% \n",
      "git-2.23.0           | 10.5 MB   | ######1    |  61% \n",
      "git-2.23.0           | 10.5 MB   | ######3    |  63% \n",
      "git-2.23.0           | 10.5 MB   | ######5    |  65% \n",
      "git-2.23.0           | 10.5 MB   | ######6    |  67% \n",
      "git-2.23.0           | 10.5 MB   | ######8    |  69% \n",
      "git-2.23.0           | 10.5 MB   | #######    |  71% \n",
      "git-2.23.0           | 10.5 MB   | #######2   |  72% \n",
      "git-2.23.0           | 10.5 MB   | #######4   |  74% \n",
      "git-2.23.0           | 10.5 MB   | #######5   |  76% \n",
      "git-2.23.0           | 10.5 MB   | #######7   |  78% \n",
      "git-2.23.0           | 10.5 MB   | #######9   |  80% \n",
      "git-2.23.0           | 10.5 MB   | ########1  |  81% \n",
      "git-2.23.0           | 10.5 MB   | ########3  |  83% \n",
      "git-2.23.0           | 10.5 MB   | ########5  |  85% \n",
      "git-2.23.0           | 10.5 MB   | ########6  |  87% \n",
      "git-2.23.0           | 10.5 MB   | ########8  |  89% \n",
      "git-2.23.0           | 10.5 MB   | #########  |  91% \n",
      "git-2.23.0           | 10.5 MB   | #########2 |  93% \n",
      "git-2.23.0           | 10.5 MB   | #########7 |  97% \n",
      "git-2.23.0           | 10.5 MB   | #########9 | 100% \n",
      "git-2.23.0           | 10.5 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/fchollet/keras.git\n",
      "  Cloning git://github.com/fchollet/keras.git to c:\\users\\asus\\appdata\\local\\temp\\pip-req-build-rbks9dv8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Asus\\anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-rbks9dv8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-rbks9dv8\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-pip-egg-info-5xa0njik'\n",
      "         cwd: C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-req-build-rbks9dv8\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Asus\\anaconda3\\lib\\tokenize.py\", line 392, in open\n",
      "        buffer = _builtin_open(filename, 'rb')\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-rbks9dv8\\\\setup.py'\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "  Downloading tf_nightly-2.5.0.dev20201225-cp38-cp38-win_amd64.whl (291.1 MB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.19.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (0.3.3)\n",
      "Collecting tf-estimator-nightly~=2.5.0.dev\n",
      "  Downloading tf_estimator_nightly-2.5.0.dev2020122501-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tb-nightly~=2.5.0.a\n",
      "  Downloading tb_nightly-2.5.0a20201225-py3-none-any.whl (12.2 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (0.35.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (3.14.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (0.11.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tf-nightly) (1.32.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tb-nightly~=2.5.0.a->tf-nightly) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.10)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n",
      "Installing collected packages: tf-estimator-nightly, tb-nightly, h5py, tf-nightly\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Asus\\\\anaconda3\\\\Lib\\\\site-packages\\\\~5py\\\\defs.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\asus\\anaconda3\\lib\\site-packages (from efficientnet) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\asus\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (1.5.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (3.3.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (8.0.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2020.10.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Installing collected packages: keras-applications, efficientnet\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZVd-g3EB9587"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d94b944fc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.signal as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from librosa import core, onset, feature, display\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import copy\n",
    "import os\n",
    "import pathlib\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import splitfolders\n",
    "import keras, keras.layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import EfficientNetB3 as efn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0aCmHE-dViu0"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"birdsong_metadata.csv\")\n",
    "#dataset.head()\n",
    "x = []\n",
    "samplerate = []\n",
    "spectrum = []\n",
    "spectrogram = []\n",
    "\n",
    "\n",
    "#Delete the useless collumns of y \n",
    "y = dataset.iloc[:, 3]\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUmiJl-LfjlO"
   },
   "source": [
    "# Convert the audios to corresponding Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uk2VcYm8m3zl",
    "outputId": "7f1f3fa8-27dc-4ada-86ed-2d7fe76f43a8"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "\n",
    "pathlib.Path('./Birdsongs_Spectrograms').mkdir(parents=True, exist_ok=True)\n",
    "birds_names = dataset.iloc[:, 3].unique()\n",
    "for birds_name in birds_names:\n",
    "  pathlib.Path(f'./Birdsongs_Spectrograms/{birds_name}').mkdir(parents=True, exist_ok=True)  \n",
    "  for i in range(len(dataset)):\n",
    "    if os.path.exists(f'./Birdsongs_Spectrograms/{dataset.iloc[i, 3]}'):\n",
    "      if len(os.listdir(f'./Birdsongs_Spectrograms/{dataset.iloc[i, 3]}')) < 3: \n",
    "        x.append(sf.read('songs/xc' + str(dataset['file_id'][i]) + '.flac'))\n",
    "        samplerate.append(x[i][1])\n",
    "        plt.specgram(x[i][0], NFFT = 2048, Fs=samplerate[i], Fc=0, noverlap=210, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        print(dataset.iloc[i, 3] + ' - ' + str(dataset.iloc[i, 0]))\n",
    "        plt.savefig('./Birdsongs_Spectrograms/' + dataset.iloc[i, 3] +'/' + str(dataset['file_id'][i]) + '.png')\n",
    "        plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "9EqItBwzb5Yp",
    "outputId": "d38a52ac-47eb-46b2-8f7e-62153870c0b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 264 files [00:00, 539.11 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176 images belonging to 88 classes.\n",
      "Found 88 images belonging to 88 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splitfolders.ratio('./Birdsongs_Spectrograms/', output = './data/', seed = 1337, ratio=(.8, .2))\n",
    "\n",
    "image_size = (224, 224, 3) \n",
    "path = \"./data/\"\n",
    "batch_size = 16\n",
    "\n",
    "train_data_generator = ImageDataGenerator(width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                          shear_range = 0.2, zoom_range = 0.1, fill_mode = 'nearest')\n",
    "train_batches = train_data_generator.flow_from_directory(path + 'train', target_size = image_size, \n",
    "                                                         class_mode = 'categorical', shuffle = False, \n",
    "                                                         batch_size = batch_size)\n",
    "\n",
    "test_data_generator = ImageDataGenerator()\n",
    "test_batches = test_data_generator.flow_from_directory(path + 'val', \n",
    "                                                 target_size = image_size, \n",
    "                                                 class_mode = 'categorical', shuffle = False, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Qn-l7FzMeHGB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 111, 111, 128)     1280      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 55, 55, 224)       258272    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 27, 27, 224)       0         \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 27, 27, 224)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 27, 27, 224)       451808    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag (None, 13, 13, 224)       0         \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 13, 13, 224)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 37856)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               3785700   \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 88)                8888      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 88)                0         \n",
      "=================================================================\n",
      "Total params: 4,546,348\n",
      "Trainable params: 4,546,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (224,224,3) into shape (224,224,3,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0005f7f8c5b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m model.fit(train_batches, steps_per_epoch = int(176/batch_size), epochs = 150, validation_data = test_batches, \n\u001b[0m\u001b[0;32m     37\u001b[0m                     validation_steps = int(88/batch_size))\n\u001b[0;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[0;32m    903\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;31m# optionally save augmented images to disk for debugging purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (224,224,3) into shape (224,224,3,3)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape=(224, 224, 1)\n",
    "model.add(Conv2D(128, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(224, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(224, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(88))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "decay_rate = learning_rate / epochs\n",
    "optimizer = SGD(lr = learning_rate, momentum = momentum, decay = decay_rate, nesterov = False)\n",
    "model.compile(optimizer = optimizer, loss =\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_batches, steps_per_epoch = int(176/batch_size), epochs = 150, validation_data = test_batches, \n",
    "                    validation_steps = int(88/batch_size))\n",
    "model.evaluate_generator(generator = test_batches, steps = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941888/43941136 [==============================] - 28s 1us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f506df348ba3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m net = tf.keras.applications.EfficientNetB3(include_top=False,                       \n\u001b[0m\u001b[0;32m      2\u001b[0m                          \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                          input_shape=image_size)   \n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\efficientnet.py\u001b[0m in \u001b[0;36mEfficientNetB3\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m                    \u001b[0mclassifier_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                    **kwargs):\n\u001b[1;32m--> 605\u001b[1;33m   return EfficientNet(\n\u001b[0m\u001b[0;32m    606\u001b[0m       \u001b[1;36m1.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m       \u001b[1;36m1.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\efficientnet.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         file_hash=file_hash)\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2233\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2234\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2236\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    660\u001b[0m   \"\"\"\n\u001b[0;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;34m'keras_version'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m     \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keras_version'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "net = tf.keras.applications.EfficientNetB3(include_top=False,                       \n",
    "                         weights='imagenet', input_tensor=None,                        \n",
    "                         input_shape=image_size)   \n",
    "x = net.output \n",
    "x = Flatten()(x) \n",
    "x = Dropout(0.5)(x) \n",
    "output_layer = Dense(len(birds_names), activation='softmax', name='softmax')(x)\n",
    "\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)      \n",
    "net_final.compile(optimizer=Adam(),                  \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "# Estimate class weights for unbalanced dataset \n",
    "class_weights = class_weight.compute_class_weight('balanced',                 \n",
    "                                                  np.unique(train_batches.classes),                  \n",
    "                                                  train_batches.classes)  \n",
    "# Define callbacks \n",
    "ModelCheck = ModelCheckpoint('models/efficientnet_checkpoint.h5', monitor='val_loss', verbose=0,                               \n",
    "                             save_best_only=True, save_weights_only=True, mode='auto', period=1) \n",
    "ReduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2,                               \n",
    "                             patience=5, min_lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(efn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
